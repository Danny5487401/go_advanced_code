<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [ginkgo](#ginkgo)
  - [使用](#%E4%BD%BF%E7%94%A8)
    - [DesctibeTable用法](#desctibetable%E7%94%A8%E6%B3%95)
    - [Measure模块测试例性能](#measure%E6%A8%A1%E5%9D%97%E6%B5%8B%E8%AF%95%E4%BE%8B%E6%80%A7%E8%83%BD)
  - [源码分析](#%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90)
    - [测试入口](#%E6%B5%8B%E8%AF%95%E5%85%A5%E5%8F%A3)
    - [运行用例](#%E8%BF%90%E8%A1%8C%E7%94%A8%E4%BE%8B)
    - [为Suite添加Specs 编写描述用例](#%E4%B8%BAsuite%E6%B7%BB%E5%8A%A0specs-%E7%BC%96%E5%86%99%E6%8F%8F%E8%BF%B0%E7%94%A8%E4%BE%8B)
  - [第三方使用-->victoria-operator](#%E7%AC%AC%E4%B8%89%E6%96%B9%E4%BD%BF%E7%94%A8--victoria-operator)
  - [参考](#%E5%8F%82%E8%80%83)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


# ginkgo


Ginkgo是一个 Go 语言的 BDD 测试框架，旨在帮助开发者编写富有表现力的全方位测试。
Ginkgo 集成了 Go 原生的库，这意味着你可以通过来运行 Ginkgo 测试套件。同时，它与断言和 mock 套件testify、富测试集go-check同样兼容。但 Ginkgo 建议的是搭配gomega库一起使用。


测试驱动开发（Test-Driven Development，TDD）和行为驱动开发（Behavior-driven development，BDD）。

TDD 的基本思路就是通过测试来推动整个开发的进行，原则就是在开发功能代码之前，先编写单元测试用例。
TDD 侧重点偏向开发，通过测试用例来规范约束开发者编写出质量更高、bug更少的代码

BDD 衍生于 TDD，主要区别就是在于测试的描述上。BDD 使用一种更通俗易懂的文字来描述测试用例，更关注需求的功能，而不是实际结果。

Ginkgo10个常用的模块：It、Context、Describe、BeforeEach、AfterEach、JustBeforeEach、BeforeSuite、AfterSuite、By、Fail


## 使用


### DesctibeTable用法
有时候很多测试例除了数据部分其他都是相同的，写很多类似的It会很繁琐，于是有Table格式出现

### Measure模块测试例性能

## 源码分析

### 测试入口

```go
func TestBook(t *testing.T) {
	// 注册 fail 函数
	RegisterFailHandler(Fail)
	RunSpecs(t, "book_test")
}

```

该函数 TestBooks 其实是 go test 标准库框架的下的一个测试用例，这也是为什么 go test 也能识别 Ginkgo 测试用例的原因。
Ginkgo 的测试用例和 go test 的测试用例并不等价，所有 Ginkgo 代码只相当于 go test 中的一个用例。既然大框架上属于 go test，那么 Ginkgo 也要遵循标准库测试的规则： 测试入口文件必须是 _test.go 结尾，否则 Ginkgo 不能识别。


```go
func RegisterFailHandler(fail types.GomegaFailHandler) {
	internalGomega(Default).ConfigureWithFailHandler(fail)
}
```

默认 gomega 初始化
```go
var Default = Gomega(internal.NewGomega(internal.FetchDefaultDurationBundle()))

```

```go
func NewGomega(bundle DurationBundle) *Gomega {
	return &Gomega{
		Fail:           nil,
		THelper:        nil,
		DurationBundle: bundle,
	}
}


// 配置失败处理
func (g *Gomega) ConfigureWithFailHandler(fail types.GomegaFailHandler) *Gomega {
	g.Fail = fail
	g.THelper = func() {}
	return g

```



### 运行用例
```go
func RunSpecs(t GinkgoTestingT, description string, args ...interface{}) bool {
	// 判断是否已经开始运行
	if suiteDidRun {
		exitIfErr(types.GinkgoErrors.RerunningSuite())
	}
	suiteDidRun = true
	err := global.PushClone()
	if err != nil {
		exitIfErr(err)
	}
	defer global.PopClone()

	suiteLabels := extractSuiteConfiguration(args)

	var reporter reporters.Reporter
	if suiteConfig.ParallelTotal == 1 { // 默认并发为 1
		reporter = reporters.NewDefaultReporter(reporterConfig, formatter.ColorableStdOut)
		outputInterceptor = internal.NoopOutputInterceptor{}
		client = nil
	} else {
		reporter = reporters.NoopReporter{}
		switch strings.ToLower(suiteConfig.OutputInterceptorMode) {
		case "swap":
			outputInterceptor = internal.NewOSGlobalReassigningOutputInterceptor()
		case "none":
			outputInterceptor = internal.NoopOutputInterceptor{}
		default:
			outputInterceptor = internal.NewOutputInterceptor()
		}
		client = parallel_support.NewClient(suiteConfig.ParallelHost)
		if !client.Connect() {
			client = nil
			exitIfErr(types.GinkgoErrors.UnreachableParallelHost(suiteConfig.ParallelHost))
		}
		defer client.Close()
	}

	writer := GinkgoWriter.(*internal.Writer)
	if reporterConfig.Verbosity().GTE(types.VerbosityLevelVerbose) && suiteConfig.ParallelTotal == 1 {
		writer.SetMode(internal.WriterModeStreamAndBuffer)
	} else {
		writer.SetMode(internal.WriterModeBufferOnly)
	}

	if reporterConfig.WillGenerateReport() {
		registerReportAfterSuiteNodeForAutogeneratedReports(reporterConfig)
	}

	// 构建树,修改状态为 PhaseBuildTree
	err = global.Suite.BuildTree()
	exitIfErr(err)
	suitePath, err := os.Getwd()
	exitIfErr(err)
	suitePath, err = filepath.Abs(suitePath)
	exitIfErr(err)

	// 运行测试用例
	passed, hasFocusedTests := global.Suite.Run(description, suiteLabels, suitePath, global.Failer, reporter, writer, outputInterceptor, interrupt_handler.NewInterruptHandler(client), client, internal.RegisterForProgressSignal, suiteConfig)
	outputInterceptor.Shutdown()

	flagSet.ValidateDeprecations(deprecationTracker)
	if deprecationTracker.DidTrackDeprecations() {
		fmt.Fprintln(formatter.ColorableStdErr, deprecationTracker.DeprecationsReport())
	}

	if !passed {
		t.Fail()
	}

	if passed && hasFocusedTests && strings.TrimSpace(os.Getenv("GINKGO_EDITOR_INTEGRATION")) == "" {
		fmt.Println("PASS | FOCUSED")
		os.Exit(types.GINKGO_FOCUS_EXIT_CODE)
	}
	return passed
}
```

```go
// 构建树
func (suite *Suite) BuildTree() error {
	// During PhaseBuildTopLevel, the top level containers are stored in suite.topLevelCotainers and entered
	// We now enter PhaseBuildTree where these top level containers are entered and added to the spec tree
	suite.phase = PhaseBuildTree
	for _, topLevelContainer := range suite.topLevelContainers {
		err := suite.PushNode(topLevelContainer)
		if err != nil {
			return err
		}
	}
	return nil
}

// 运行
func (suite *Suite) Run(description string, suiteLabels Labels, suitePath string, failer *Failer, reporter reporters.Reporter, writer WriterInterface, outputInterceptor OutputInterceptor, interruptHandler interrupt_handler.InterruptHandlerInterface, client parallel_support.Client, progressSignalRegistrar ProgressSignalRegistrar, suiteConfig types.SuiteConfig) (bool, bool) {
	if suite.phase != PhaseBuildTree {
		panic("cannot run before building the tree = call suite.BuildTree() first")
	}
	ApplyNestedFocusPolicyToTree(suite.tree)
	specs := GenerateSpecsFromTreeRoot(suite.tree)
	specs, hasProgrammaticFocus := ApplyFocusToSpecs(specs, description, suiteLabels, suiteConfig)

	suite.phase = PhaseRun
	suite.client = client
	suite.failer = failer
	suite.reporter = reporter
	suite.writer = writer
	suite.outputInterceptor = outputInterceptor
	suite.interruptHandler = interruptHandler
	suite.config = suiteConfig

	if suite.config.Timeout > 0 {
		suite.deadline = time.Now().Add(suite.config.Timeout)
	}

	cancelProgressHandler := progressSignalRegistrar(suite.handleProgressSignal)

	// RunSpecs 便会开始遍历树
	success := suite.runSpecs(description, suiteLabels, suitePath, hasProgrammaticFocus, specs)

	cancelProgressHandler()

	return success, hasProgrammaticFocus
}


func (suite *Suite) runSpecs(description string, suiteLabels Labels, suitePath string, hasProgrammaticFocus bool, specs Specs) bool {
	numSpecsThatWillBeRun := specs.CountWithoutSkip()

	suite.report = types.Report{
		SuitePath:                 suitePath,
		SuiteDescription:          description,
		SuiteLabels:               suiteLabels,
		SuiteConfig:               suite.config,
		SuiteHasProgrammaticFocus: hasProgrammaticFocus,
		PreRunStats: types.PreRunStats{
			TotalSpecs:       len(specs),
			SpecsThatWillRun: numSpecsThatWillBeRun,
		},
		StartTime: time.Now(),
	}

	suite.reporter.SuiteWillBegin(suite.report)
	if suite.isRunningInParallel() {
		suite.client.PostSuiteWillBegin(suite.report)
	}

	// 初始化成功状态
	suite.report.SuiteSucceeded = true

	suite.runReportSuiteNodesIfNeedBe(types.NodeTypeReportBeforeSuite)

	ranBeforeSuite := suite.report.SuiteSucceeded
	if suite.report.SuiteSucceeded {
		// 前置测试依赖
		suite.runBeforeSuite(numSpecsThatWillBeRun)
	}

	if suite.report.SuiteSucceeded {
		groupedSpecIndices, serialGroupedSpecIndices := OrderSpecs(specs, suite.config)
		nextIndex := MakeIncrementingIndexCounter()
		if suite.isRunningInParallel() {
			nextIndex = suite.client.FetchNextCounter
		}

		for {
			groupedSpecIdx, err := nextIndex()
			if err != nil {
				suite.report.SpecialSuiteFailureReasons = append(suite.report.SpecialSuiteFailureReasons, fmt.Sprintf("Failed to iterate over specs:\n%s", err.Error()))
				suite.report.SuiteSucceeded = false
				break
			}

			if groupedSpecIdx >= len(groupedSpecIndices) {
				if suite.config.ParallelProcess == 1 && len(serialGroupedSpecIndices) > 0 {
					groupedSpecIndices, serialGroupedSpecIndices, nextIndex = serialGroupedSpecIndices, GroupedSpecIndices{}, MakeIncrementingIndexCounter()
					suite.client.BlockUntilNonprimaryProcsHaveFinished()
					continue
				}
				break
			}

			// the complexity for running groups of specs is very high because of Ordered containers and FlakeAttempts
			// we encapsulate that complexity in the notion of a Group that can run
			// Group is really just an extension of suite so it gets passed a suite and has access to all its internals
			// Note that group is stateful and intended for single use!
			newGroup(suite).run(specs.AtIndices(groupedSpecIndices[groupedSpecIdx]))
		}

		if specs.HasAnySpecsMarkedPending() && suite.config.FailOnPending {
			suite.report.SpecialSuiteFailureReasons = append(suite.report.SpecialSuiteFailureReasons, "Detected pending specs and --fail-on-pending is set")
			suite.report.SuiteSucceeded = false
		}
	}

	if ranBeforeSuite { // 后置测试依赖
		suite.runAfterSuiteCleanup(numSpecsThatWillBeRun)
	}

	interruptStatus := suite.interruptHandler.Status()
	if interruptStatus.Interrupted() {
		suite.report.SpecialSuiteFailureReasons = append(suite.report.SpecialSuiteFailureReasons, interruptStatus.Cause.String())
		suite.report.SuiteSucceeded = false
	}
	suite.report.EndTime = time.Now()
	suite.report.RunTime = suite.report.EndTime.Sub(suite.report.StartTime)
	if !suite.deadline.IsZero() && suite.report.EndTime.After(suite.deadline) {
		suite.report.SpecialSuiteFailureReasons = append(suite.report.SpecialSuiteFailureReasons, "Suite Timeout Elapsed")
		suite.report.SuiteSucceeded = false
	}

	suite.runReportSuiteNodesIfNeedBe(types.NodeTypeReportAfterSuite)
	suite.reporter.SuiteDidEnd(suite.report)
	if suite.isRunningInParallel() {
		suite.client.PostSuiteDidEnd(suite.report)
	}

	return suite.report.SuiteSucceeded
}

```


### 为Suite添加Specs 编写描述用例
```go
func Describe(text string, args ...interface{}) bool {
	// 推送 用例容器 
	return pushNode(internal.NewNode(deprecationTracker, types.NodeTypeContainer, text, args...))
}
```



初始化节点
```go
func NewNode(deprecationTracker *types.DeprecationTracker, nodeType types.NodeType, text string, args ...interface{}) (Node, []error) {
	baseOffset := 2
	node := Node{
		ID:                   UniqueNodeID(),
		NodeType:             nodeType,
		Text:                 text,
		Labels:               Labels{},
		CodeLocation:         types.NewCodeLocation(baseOffset),
		NestingLevel:         -1,
		PollProgressAfter:    -1,
		PollProgressInterval: -1,
		GracePeriod:          -1,
	}

    // ...
	
	// First get the CodeLocation up-to-date
	for _, arg := range args {
		switch v := arg.(type) {
		case Offset:
			node.CodeLocation = types.NewCodeLocation(baseOffset + int(v))
		case types.CodeLocation:
			node.CodeLocation = v
		default:
			remainingArgs = append(remainingArgs, arg)
		}
	}

	labelsSeen := map[string]bool{}
	trackedFunctionError := false
	args = remainingArgs
	remainingArgs = []interface{}{}
	// now process the rest of the args
	for _, arg := range args {
		switch t := reflect.TypeOf(arg); {
		case t == reflect.TypeOf(float64(0)):
			break // ignore deprecated timeouts
        // ...
		
		// 函数类型
		case t.Kind() == reflect.Func:
			if nodeType.Is(types.NodeTypeContainer) {
				if node.Body != nil {
					appendError(types.GinkgoErrors.MultipleBodyFunctions(node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
				if t.NumOut() > 0 || t.NumIn() > 0 {
					appendError(types.GinkgoErrors.InvalidBodyTypeForContainer(t, node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
				body := arg.(func())
				node.Body = func(SpecContext) { body() }
			} 
			
			// ...其他类型
			
			else if nodeType.Is(types.NodeTypeSynchronizedAfterSuite) {
				if node.SynchronizedAfterSuiteAllProcsBody != nil && node.SynchronizedAfterSuiteProc1Body != nil {
					appendError(types.GinkgoErrors.MultipleBodyFunctions(node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
				body, hasContext := extractBodyFunction(deprecationTracker, node.CodeLocation, arg)
				if body == nil {
					appendError(types.GinkgoErrors.InvalidBodyType(t, node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
				if node.SynchronizedAfterSuiteAllProcsBody == nil {
					node.SynchronizedAfterSuiteAllProcsBody, node.SynchronizedAfterSuiteAllProcsBodyHasContext = body, hasContext
				} else if node.SynchronizedAfterSuiteProc1Body == nil {
					node.SynchronizedAfterSuiteProc1Body, node.SynchronizedAfterSuiteProc1BodyHasContext = body, hasContext
				}
			} else {
				if node.Body != nil {
					appendError(types.GinkgoErrors.MultipleBodyFunctions(node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
				node.Body, node.HasContext = extractBodyFunction(deprecationTracker, node.CodeLocation, arg)
				if node.Body == nil {
					appendError(types.GinkgoErrors.InvalidBodyType(t, node.CodeLocation, nodeType))
					trackedFunctionError = true
					break
				}
			}
		default:
			remainingArgs = append(remainingArgs, arg)
		}
	}

	// validations 校验 ...


	if len(errors) > 0 {
		return Node{}, errors
	}

	return node, errors
}

```

推入节点
```go
func pushNode(node internal.Node, errors []error) bool {
	exitIfErrors(errors)
	// 全局压入 node 
	exitIfErr(global.Suite.PushNode(node))
	return true
}
```

```go
func (suite *Suite) PushNode(node Node) error {
	// 节点类型判断...
	// ...

	if node.NodeType == types.NodeTypeContainer {
		// During PhaseBuildTopLevel we only track the top level containers without entering them
		// We only enter the top level container nodes during PhaseBuildTree
		//
		// This ensures the tree is only constructed after `go spec` has called `flag.Parse()` and gives
		// the user an opportunity to load suiteConfiguration information in the `TestX` go spec hook just before `RunSpecs`
		// is invoked.  This makes the lifecycle easier to reason about and solves issues like #693.
		if suite.phase == PhaseBuildTopLevel {
			suite.topLevelContainers = append(suite.topLevelContainers, node)
			return nil
		}
		if suite.phase == PhaseBuildTree { // 在 PhaseBuildTree 阶段，将所有顶层容器统一在一棵多叉树下
			parentTree := suite.tree
			suite.tree = &TreeNode{Node: node}
			parentTree.AppendChild(suite.tree)
			err := func() (err error) {
	            // ..
				node.Body(nil)
				return err
			}()
			suite.tree = parentTree
			return err
		}
	} else {
		suite.tree.AppendChild(&TreeNode{Node: node})
		return nil
	}

	return nil
}
```

## 第三方使用-->victoria-operator

测试套件前后依赖

```go
// https://github.com/VictoriaMetrics/operator/blob/3c6c341734428128034384eeec0925277beadca5/internal/controller/operator/suite_test.go

var cfg *rest.Config
var k8sClient client.Client
var testEnv *envtest.Environment

// 前置 k8s 组件依赖
var _ = BeforeSuite(func(done Done) {
	l := zap.New(zap.WriteTo(GinkgoWriter), zap.Level(zapcore.DebugLevel))
	logf.SetLogger(l)
	By("bootstrapping test environment")
	testEnv = &envtest.Environment{
		CRDDirectoryPaths:        []string{filepath.Join("..", "..", "..", "config", "crd", "overlay")},
		UseExistingCluster:       ptr.To(true),
		AttachControlPlaneOutput: true,
		ErrorIfCRDPathMissing:    true,

		// The BinaryAssetsDirectory is only required if you want to run the tests directly
		// without call the makefile target test. If not informed it will look for the
		// default path defined in controller-runtime which is /usr/local/kubebuilder/.
		// Note that you must have the required binaries setup under the bin directory to perform
		// the tests directly. When we run make test it will be setup and used automatically.
		BinaryAssetsDirectory: filepath.Join("..", "..", "..", "bin", "k8s",
			fmt.Sprintf("1.30.0-%s-%s", runtime.GOOS, runtime.GOARCH)),
	}

	var err error
	cfg, err = testEnv.Start()
    // ...

	close(done)
})

var _ = Describe("test reconciling vmagent Controller", func() {
	Context("run controller", func() {
	})
})

var _ = AfterSuite(func() {
	By("tearing down the test environment")
	err := testEnv.Stop()
	Expect(err).ToNot(HaveOccurred())
})

```


定义测试用例
```go
package v1beta1

import (
	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
	"gopkg.in/yaml.v2"
)

var _ = Describe("VMRule Webhook", func() {
	Context("When creating VMRule under Validating Webhook", func() {
		
		// 表格的方式
		DescribeTable("fails validation",
			func(srcYAML string, wantErr string) {
				var vmr VMRule
				Expect(yaml.Unmarshal([]byte(srcYAML), &vmr)).To(Succeed())
				Expect(vmr.Validate()).To(MatchError(wantErr))
			},
			Entry("bad tenant", `
      apiVersion: operator.victoriametrics.com/v1beta1
      kind: VMRule
      metadata:
        name: bad-tenant
      spec:
        groups:
        - name: kafka
          tenant: bad-value
          rules:
          - alert: coordinator down
            expr: ml_app_gauge{exec_context="consumer_group_state"} == 0
            for: 60s
            labels:
              severity: critical
              job: "{{ $labels.job }}"
            annotations:
              value: "{{ $value }}"
              description: 'kafka coorinator is down'

        `, `at idx=0 bad tenant="bad-value": cannot parse account_id: "bad-value" as int32, err: strconv.ParseInt: parsing "bad-value": invalid syntax`),
		// ...
			Entry("duplicate rules", `
      apiVersion: operator.victoriametrics.com/v1beta1
      kind: VMRule
      metadata:
        name: duplicate-rules
      spec:
        groups:
        - name: kafka
          rules:
          - alert: some indicator
            expr: ml_app_gauge{exec_context="consumer_group_state"} == 0
            for: 60s
          - alert: some indicator
            expr: ml_app_gauge{exec_context="consumer_group_state"} == 0
            for: 60s
        `, `validation failed for VMRule: / group: kafka err: "alerting rule \"some indicator\"; expr: \"ml_app_gauge{exec_context=\\\"consumer_group_state\\\"} == 0\"" is a duplicate in group`),
		)
        // ...
	})
})

```

命令行执行
```makefile
# https://github.com/VictoriaMetrics/operator/blob/9572ed275e48f1ceb6a3aac52e6761f0b6f3f741/Makefile

.PHONY: ginkgo
ginkgo:
	$(call go-install-tool,$(GINKGO_BIN),github.com/onsi/ginkgo/v2/ginkgo,$(GINKGO_VERSION))
	
.PHONY: test-e2e  # Run the e2e tests against a Kind k8s instance that is spun up.
test-e2e: load-kind ginkgo
	$(GINKGO_BIN) -timeout=30m ./test/e2e/
	$(GINKGO_BIN) -procs=1 -timeout=20m ./test/e2e/childobjects/
```

## 参考
- https://onsi.github.io/ginkgo/
- [ginkgo 中文文档](https://ke-chain.github.io/ginkgodoc/)
- [Go：基于BDD的测试框架 Ginkgo 简介及实践](https://cloud.tencent.com/developer/article/2403092)
- [Ginkgo 测试框架实现解析](https://www.lyyyuna.com/2022/05/12/inside-the-ginkgo/)
- [一个 Ginkgo 集测优化案例](https://juejin.cn/post/7527137091194798116)