#缓存
![](.cache_images/cache.png)

    图中是一个存储结构示意图，cpu和主存直接使用的是L3的结构。金字塔越上面，相互之间的访问速度越快但是数据量越小，越往下访问速度越慢但数据量越大。

    在单核CPU结构中，为了缓解CPU指令流水中cycle冲突，L1分成了指令（L1P）和数据（L1D）两部分，而L2则是指令和数据共存。多核CPU增设了L3三级缓存，L1和L2是CPU核自己使用，但是L3缓存是多核共享的

# cache局部性原理

局部性分为时间局部性和空间局部性

    时间局部性是说，当前访问到的数据随后时间也可能会访问到。

    空间局部性是指，当前访问的的地址附近的地址，之后可能会被访问到。

    根据局部性原理，我们把容易访问到的数据缓存在cache中，这样可以提高数据访问速度和效率

cache伪共享
![](.cache_images/false_sharing.png)

    处理器和主存使用缓存行(cache lines)进行数据交换。一个缓存行是一个64 byte的内存块，它在内存和缓存系统之间进行交换。每个内核会分配它自己需要的cache副本。

    当多线程并行运行，正在访问相同数据，甚至是相邻的数据单元，他们会访问相同的缓存行。任何内核上运行的任何线程能够从相同的缓存行获取各自的拷贝。
    
    如果给一个内核，他上面的线程修改它的cache行副本，然后会通过硬件MESI机制，同一cache行的所有其他副本都会被标记为无效。当一个线程尝试读写脏cache行，需要重新访问主存去获取新的cache行副本(大约要100~300个时钟周期)